{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fd9104-3f8c-4c4a-a595-07ece28bf42a",
   "metadata": {},
   "source": [
    "This notebook shows how to apply CNN to predict the global temperature map, based on the 1-D time series of CO2 & CH4.\n",
    "\n",
    "By Weiwei Zhan & Francesco Immorlano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80778f5a-2a51-4ce9-9c44-8a9e5ff9bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from utils import * \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26208e-b079-4b69-83b3-cf90a85f64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "train_path = os.path.join(cwd,'Data','train_val')\n",
    "test_path  = os.path.join(cwd,'Data','test')\n",
    "\n",
    "make_dir(train_path)\n",
    "make_dir(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28aad0-bbcd-4cfc-81d3-75e9ff3c0cec",
   "metadata": {},
   "source": [
    "### 1. data preprocssing: prepare data for training & test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c24895f-2b53-4816-a58d-849fba775e4f",
   "metadata": {},
   "source": [
    "#### import data as training & test sets\n",
    "\n",
    "Here we train CNN using simulations from 3 historical and 3 future scenarios. Then we test the trained NN using the ssp245 scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f0d37-2bc5-486d-a3e5-6e2c0679f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_files = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\",\"hist-GHG\",\"hist-aer\"]\n",
    "X_train_xr, X_length  = prepare_predictor(train_files,train_path)\n",
    "y_train_xr, y_length  = prepare_predictand(train_files,train_path)\n",
    "\n",
    "# Test set\n",
    "X_test_xr, _ = prepare_predictor('ssp245', data_path=test_path,time_reindex=False)\n",
    "y_test_xr, _ = prepare_predictand('ssp245',data_path=test_path,time_reindex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8900c1-7179-4fe2-b9a4-6e652588e8b6",
   "metadata": {},
   "source": [
    "#### select relevant variables\n",
    "\n",
    "predictors: CO2 & CH4 <br/>\n",
    "predictand: tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07508632-804a-4be2-911e-20ed7e4ebbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({\"CO2\": X_train_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_train_xr[\"CH4\"].data\n",
    "                          }, index=X_train_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "X_test_df  = pd.DataFrame({\"CO2\": X_test_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_test_xr[\"CH4\"].data\n",
    "                          }, index=X_test_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "y_train = y_train_xr['tas'].data\n",
    "y_test  = y_test_xr['tas'].data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c3c9fd-4683-4407-aa12-d9acc489425e",
   "metadata": {},
   "source": [
    "This is how our predictors & predictand data look like. Our predictors are **1-D** time series of CO2 & CH4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9852d6-9f9d-46e4-ae2e-63061fb18a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298bd51-b904-4863-af80-efe62eebc96c",
   "metadata": {},
   "source": [
    "The predictand tas is **2-D** map - this point is different from the NN case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69801cc4-7ff9-4e48-bbf2-a820e8c4b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.flip(y_train[0],axis=0),cmap='RdBu_r',vmin=-3,vmax=3)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403202e-8451-4c56-820d-15ee05305bfb",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8fb977-a914-49a3-9175-60947499845a",
   "metadata": {},
   "source": [
    "Let's normalize the input predictors by there mean & standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29c597-d7d1-4dc6-a814-d048b8f69969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "mean, std = X_train_df.mean(), X_train_df.std()\n",
    "\n",
    "X_train_df   = (X_train_df - mean)/std\n",
    "X_test_df    = (X_test_df - mean)/std\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9602c-68d9-4900-997a-a7d5eff5265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd5b12-b818-452e-a664-5f2743618281",
   "metadata": {},
   "source": [
    "### 2. Define the CNN architecture\n",
    "\n",
    "\n",
    "The CNN architecture used here consists of several upsampling blocks. \n",
    "\n",
    "We set the dimensions of the hidden layers (i.e., number of neurons) in order to reach the size of the target maps (96x144) in a proportional way (in particular by doubling the dimensions in each upsampling block) through the various upsampling blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d9d80e-94c2-45d4-a573-72725767fc67",
   "metadata": {},
   "source": [
    "![CNN_structure](https://drive.google.com/uc?export=view&id=18a4aKFf62qWgFZP57HloHKrzHdZpmqjO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03a6c4-d684-40d0-93d9-dc3f71b42792",
   "metadata": {},
   "source": [
    "Here are the hyperparameters for the CNN training. Note that these hyperparameters here are for demonstration purposes only and they are not optimized.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf94451-4cfd-43e0-8c10-c687f0585e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters  = 32  # number of filters\n",
    "n_neurons  = 32  # number of neurons in the Dense layer\n",
    "activation     = 'relu' # activation function\n",
    "kernel_size    = 4\n",
    "learning_rate  = 0.001\n",
    "minibatch_size = 64\n",
    "num_epochs     = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878113d1-b59a-4c17-b336-17ebef191a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(n_filters*12*18, input_shape=(X_train.shape[1],), activation=activation)) # shape: (6912,1)\n",
    "model.add(Reshape((12,18,n_filters))) # shape: (12,18,32)\n",
    "\n",
    "# Upsample to 24x36\n",
    "model.add(Conv2DTranspose(filters=n_filters, kernel_size=kernel_size, \n",
    "                          activation=activation, strides=2, padding='same')) # shape: (24,36,32)\n",
    "\n",
    "# Upsample to 48x72\n",
    "model.add(Conv2DTranspose(filters=n_filters, kernel_size=kernel_size, \n",
    "                          activation=activation, strides=2, padding='same')) # shape: (48,72,32)\n",
    "\n",
    "# Upsample to 96x144\n",
    "model.add(Conv2DTranspose(filters=n_filters, kernel_size=kernel_size, \n",
    "                          activation=activation, strides=2, padding='same')) # shape: (96,144,32)\n",
    "\n",
    "model.add(Conv2DTranspose(filters=1, kernel_size=kernel_size, activation=\"linear\", padding=\"same\")) # shape: (96,144,1)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4073881f-dd6f-45e0-ac03-a955b326f0cb",
   "metadata": {},
   "source": [
    "### 3. Train & save the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f2e496-2f3b-4b68-970c-47c4e1d98154",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size      = minibatch_size,\n",
    "                    epochs          = num_epochs,\n",
    "                    validation_split= 0.2, \n",
    "                    verbose         = 1,\n",
    "                    callbacks       = [early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af987b91-f5b0-4e62-9175-44ca18252f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44074a-2adc-4d54-80bf-a7a85e93eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(cwd,'saved_model')\n",
    "make_dir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56a1b6-79fc-4345-9bb3-e6c5651c6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save(os.path.join(model_path,'CNN_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb969b7f-8c2b-47b0-9f43-4bc68c16ad3b",
   "metadata": {},
   "source": [
    "### 4. Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1570f-7534-44d1-9f0f-84c4839af9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the saved model\n",
    "model = load_model(os.path.join(model_path,'CNN_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef677d-5222-4544-b564-19b05d9fdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pre = model.predict(X_test)\n",
    "y_test_pre = y_test_pre.reshape(y_test_pre.shape[0], 96, 144)\n",
    "y_test_pre = xr.Dataset(coords={'time': X_test_xr.time.values, \n",
    "                               'latitude': X_test_xr.latitude.values, \n",
    "                               'longitude': X_test_xr.longitude.values},\n",
    "                       data_vars=dict(tas=(['time', 'latitude', 'longitude'], y_test_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a671c19-ce52-4157-ab2b-58a4693f966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15,12),ncols=2,nrows=3)\n",
    "\n",
    "yrs = [2030, 2050, 2100]\n",
    "vmin, vmax    = -6, 6\n",
    "cmap = 'RdBu_r'\n",
    "y_test_pre.tas.sel(time=yrs[0]).plot(ax=axes[0,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[0]).plot(ax=axes[0,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[1]).plot(ax=axes[1,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[1]).plot(ax=axes[1,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "y_test_pre.tas.sel(time=yrs[2]).plot(ax=axes[2,0], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "y_test_xr.tas.sel(time=yrs[2]).plot(ax=axes[2,1], vmin=vmin, vmax=vmax,cmap=cmap)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # left column: model prediction\n",
    "    if i % 2 == 0:\n",
    "        ax.set_title(f'tas model prediction (year = {yrs[i//2]})',fontweight='bold')\n",
    "    # right column: truth tas from ssp245 simulations\n",
    "    else:\n",
    "        ax.set_title(f'tas truth (year = {yrs[i//2]})',fontweight='bold')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e52af5-0e3a-4d96-9014-ddc59f550db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a41c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921e8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aca61c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
